# # CrudAI Chat App

[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat&logo=FastAPI&logoColor=white)](https://fastapi.tiangolo.com/)
[![Auth0](https://img.shields.io/badge/Auth0-EB5424?style=flat&logo=auth0&logoColor=white)](https://auth0.com/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://docker.com)

A full-stack chat application with Auth0 authentication and local AI integration via Ollama.

## Features

- **Auth0 Authentication**: Secure JWT-based user authentication
- **Local AI Integration**: Ollama-powered chat responses (llama3.2:3b)
- **Persistent Storage**: SQLite database with auto-migrations
- **Real-time Chat**: Interactive chat interface with sidebar management
- **Docker Support**: Multi-container setup with health checks
- **Modern UI**: Responsive design with TypeScript frontend

## Quick Start

### Prerequisites
- Node.js 18+
- Python 3.9+
- Docker & Docker Compose
- Ollama (for AI features)
- Auth0 account

### Setup

1. **Clone repository:**
```bash
git clone https://github.com/timoelan/CrudAiApp.git
cd CrudAiApp
```

2. **Install Ollama and model:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama serve
ollama pull llama3.2:3b
```

3. **Configure Auth0:**

Create a Single Page Application in [Auth0 Dashboard](https://auth0.com):
- **Application Type:** Single Page Application
- **Allowed Callback URLs:** `http://localhost:5173`
- **Allowed Web Origins:** `http://localhost:5173`
- **Allowed Logout URLs:** `http://localhost:5173`

Create an API in Auth0:
- **Identifier:** `https://crudai-api`
- **Signing Algorithm:** RS256

4. **Environment setup:**

Frontend (.env):
```bash
cd client
cp .env.example .env
# Add your Auth0 values
```

Backend (.env):
```bash
cd server/config
cp .env.example .env
# Add your Auth0 values
```

5. **Start with Docker:**
```bash
cd docker
docker-compose up --build -d
```

6. **Access:**
- **Frontend:** http://localhost:5173
- **Backend:** http://localhost:8000
- **API Docs:** http://localhost:8000/docs

## Project Structure

```
CrudAiApp/
‚îú‚îÄ‚îÄ client/                 # Frontend (Vite + TypeScript)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.ts        # Application entry
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.ts        # Auth0 service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts         # Backend API client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.ts        # Chat interface
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sidebar.ts     # Chat management
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ server/                 # Backend (FastAPI + Python)
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ main.py        # FastAPI application
‚îÇ       ‚îú‚îÄ‚îÄ auth_service.py # JWT verification
‚îÇ       ‚îú‚îÄ‚îÄ ai_service.py  # Ollama integration
‚îÇ       ‚îú‚îÄ‚îÄ database.py    # SQLAlchemy setup
‚îÇ       ‚îú‚îÄ‚îÄ models.py      # Database models
‚îÇ       ‚îî‚îÄ‚îÄ routes.py      # API endpoints
‚îú‚îÄ‚îÄ docker/                 # Docker configuration
‚îÇ   ‚îú‚îÄ‚îÄ server.Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ client.Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yaml
‚îî‚îÄ‚îÄ docs/                   # Documentation
    ‚îú‚îÄ‚îÄ API_ENDPOINTS_GUIDE.md
    ‚îî‚îÄ‚îÄ OLLAMA_INTEGRATION_GUIDE.md
```

## API Endpoints

All endpoints require Bearer JWT token authentication.

### User Management
- `GET /users/me` - Get current user
- `PUT /users/me` - Update user profile

### Chat Management
- `GET /chats` - Get user chats
- `POST /chats` - Create new chat
- `GET /chats/{id}` - Get specific chat
- `PUT /chats/{id}` - Update chat
- `DELETE /chats/{id}` - Delete chat

### Messages
- `GET /messages/{chat_id}` - Get chat messages
- `POST /messages` - Send new message

### AI Integration
- `POST /ai/generate/{chat_id}` - Generate AI response

## Development

### Local Development (without Docker)

**Backend:**
```bash
cd server/src
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Frontend:**
```bash
cd client
npm install
npm run dev
```

## Troubleshooting

### Auth0 Login Issues
```bash
# Check Auth0 configuration
echo $VITE_AUTH0_DOMAIN
echo $VITE_AUTH0_CLIENT_ID

# Ensure callback URL is correct in Auth0 Dashboard
```

### AI Not Responding
```bash
# Check if Ollama is running
curl http://localhost:11434/api/version

# Start Ollama if not running
ollama serve

# Check available models
ollama list
```

### Database Issues
```bash
# Check database file
ls -la server/src/crudai.db

# Test SQLite directly
sqlite3 server/src/crudai.db "SELECT * FROM chats LIMIT 5;"
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License.

---
## üèóÔ∏è Architektur

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Production Architecture                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Frontend (React-like TypeScript)                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Auth0 SPA Client (JWT Tokens)                        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Chat UI (Messages, Sidebar)                          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ API Client (HTTP + CORS)                             ‚îÇ
‚îÇ                            ‚îÇ                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ              Backend (FastAPI)                     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ JWT Verification (JWKS)                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ CRUD API Routes                               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Ollama AI Integration                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ SQLAlchemy ORM                                ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                            ‚îÇ                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                    Data Layer                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ SQLite Database (crudai.db)                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ Ollama (llama3.2:3b)                         ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **N√ºtzliche Kommandos**
```bash
# Logs anschauen
docker-compose -f docker/docker-compose.yaml logs -f

# Services neustarten
docker-compose -f docker/docker-compose.yaml restart

# Alles stoppen
docker-compose -f docker/docker-compose.yaml down

# Setup-Script ausf√ºhren
./scripts/setup.sh
```

## üìö API Dokumentation

### **Authentifizierte Endpoints**

Alle Endpoints ben√∂tigen einen **Bearer JWT Token** im Authorization Header.

#### **User Management**
- `GET /users/me` - Aktuellen Benutzer abrufen
- `PUT /users/me` - Benutzerprofil aktualisieren

#### **Chat Management**  
- `GET /chats` - Alle Benutzer-Chats
- `POST /chats` - Neuen Chat erstellen
- `GET /chats/{id}` - Spezifischen Chat abrufen
- `PUT /chats/{id}` - Chat aktualisieren
- `DELETE /chats/{id}` - Chat l√∂schen

#### **Messages**
- `GET /messages/{chat_id}` - Chat-Nachrichten
- `POST /messages` - Neue Nachricht senden

#### **AI Integration**
- `POST /ai/generate/{chat_id}` - KI-Antwort generieren

Detaillierte API-Dokumentation findest du in [`docs/API_ENDPOINTS_GUIDE.md`](docs/API_ENDPOINTS_GUIDE.md).

## üîß Konfiguration

### **Ollama Modelle**

#### **Verf√ºgbare Modelle:**
```bash
# Empfohlen f√ºr Chat (schnell, gut)
ollama pull llama3.2:3b

# Sehr schnell (weniger genau)
ollama pull llama3.2:1b  

# Gr√∂√üer, sehr gut (mehr RAM)
ollama pull mistral:7b

# F√ºr Code-Generierung
ollama pull codellama:7b
```

#### **Modell wechseln:**
```python
# In server/src/ai_service.py
self.model = "mistral:7b"  # Oder ein anderes Modell
```

Vollst√§ndige Ollama-Integration findest du in [`docs/OLLAMA_INTEGRATION_GUIDE.md`](docs/OLLAMA_INTEGRATION_GUIDE.md).

## üîç Troubleshooting

### **H√§ufige Probleme:**

#### **1. Auth0 Login funktioniert nicht**
```bash
# Pr√ºfe Auth0-Konfiguration
echo $VITE_AUTH0_DOMAIN
echo $VITE_AUTH0_CLIENT_ID

# Stelle sicher, dass Callback URL korrekt ist
# Auth0 Dashboard > Applications > Settings > Allowed Callback URLs
# Muss enthalten: http://localhost:5173
```

#### **2. AI antwortet nicht (503 Error)**
```bash
# Pr√ºfe ob Ollama l√§uft
curl http://localhost:11434/api/version

# Ollama starten falls nicht l√§uft
ollama serve

# Modell pr√ºfen
ollama list
```

#### **3. Datenbank-Probleme**
```bash
# Datenbank-Datei pr√ºfen  
ls -la server/src/crudai.db

# SQLite direkt testen
sqlite3 server/src/crudai.db "SELECT * FROM chats LIMIT 5;"
```

#### **4. Docker-Container-Probleme**
```bash
# Container-Status pr√ºfen
docker ps

# Logs √ºberpr√ºfen
docker-compose -f docker/docker-compose.yaml logs backend
docker-compose -f docker/docker-compose.yaml logs frontend

# Container neu bauen
docker-compose -f docker/docker-compose.yaml up --build --force-recreate
```

## üìä Performance & Skalierung

### **Aktuelle Limits:**
- **SQLite:** Bis ~100k Nachrichten (f√ºr mehr: PostgreSQL)
- **Ollama:** Lokaler RAM-basiert (3B Modell = ~4GB RAM)
- **Auth0:** 7,000 aktive Benutzer (kostenlos)

### **Produktions-Optimierungen:**
- **Datenbank:** Wechsel zu PostgreSQL
- **Ollama:** GPU-Beschleunigung aktivieren
- **Caching:** Redis f√ºr Session-Management
- **Load Balancing:** Nginx f√ºr mehrere Backend-Instanzen

## ü§ù Contributing

Contributions sind willkommen! Bitte:

1. **Fork** das Repository
2. **Branch** erstellen (`git checkout -b feature/neue-funktion`)
3. **Commit** deine Changes (`git commit -m 'Neue Funktion hinzugef√ºgt'`)
4. **Push** zum Branch (`git push origin feature/neue-funktion`)
5. **Pull Request** √∂ffnen


## üôè Credits

- **FastAPI** - Modernes Python Web Framework
- **Auth0** - Authentifizierung als Service
- **Ollama** - Lokale LLM-Runtime
- **Vite** - Schneller Frontend-Build-Tool
- **SQLAlchemy** - Python ORM
- **TypeScript** - Typsichere JavaScript-Entwicklung

---

**‚≠ê Star das Repository wenn es dir geholfen hat!**

**üêõ Issues melden:** [GitHub Issues](https://github.com/timoelan/CrudAiApp/issues)

**üìß Kontakt:** [GitHub Profile](https://github.com/timoelan)
